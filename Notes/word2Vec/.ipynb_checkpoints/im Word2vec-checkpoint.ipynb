{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re # for preprocessing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time # To time the operations\n",
    "from collections import defaultdict # for word frequency\n",
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import logging # setting up the loggings to moniter gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt='%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/en_core_web_sm\n",
      "-->\n",
      "/Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "spacy.cli.download(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['raw_character_text', 'spoken_words'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/simpsons_dataset.csv')\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158314, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    17814\n",
       "spoken_words          26459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    0\n",
       "spoken_words          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z]+\", ' ', str(row)).lower() for row in df['spoken_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 0.83 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t)/ 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92173, 1)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Gensim Phrases package to automatically detect common phrases (bigrams) from a list of sentences. https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "The main reason we do this is to catch words like \"mr_burns\" or \"bart_simpson\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp37-cp37m-macosx_10_9_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages (from gensim) (1.18.5)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-4.1.2-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 14.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-4.1.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:13:36: collecting all words and their counts\n",
      "INFO - 00:13:36: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #10000, processed 67820 words and 51066 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #20000, processed 141206 words and 96869 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #30000, processed 208928 words and 133765 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #40000, processed 271322 words and 166656 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #50000, processed 335262 words and 199086 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #60000, processed 402266 words and 232305 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #70000, processed 469471 words and 265025 word types\n",
      "INFO - 00:13:36: PROGRESS: at sentence #80000, processed 536207 words and 296899 word types\n",
      "INFO - 00:13:37: PROGRESS: at sentence #90000, processed 604295 words and 327277 word types\n",
      "INFO - 00:13:37: collected 333517 word types from a corpus of 619666 words (unigram + bigrams) and 92173 sentences\n",
      "INFO - 00:13:37: using 333517 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:13:58: source_vocab length 333517\n",
      "INFO - 00:14:01: Phraser built with 136 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30248"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most Frequent Words\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'm', 'oh', 'don_t', 'will', 'like', 'know', 'hey', 'think', 'right']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why I seperate the training of the model in 3 steps:\n",
    "I prefer to separate the training in 3 distinctive steps for clarity and monitoring.\n",
    "\n",
    "1. Word2Vec():\n",
    "In this first step, I set up the parameters of the model one-by-one.\n",
    "I do not supply the parameter sentences, and therefore leave the model uninitialized, purposefully.\n",
    "\n",
    "2. build_vocab():\n",
    "Here it builds the vocabulary from a sequence of sentences and thus initialized the model.\n",
    "With the loggings, I can follow the progress and even more important, the effect of min_count and sample on the word corpus. I noticed that these two parameters, and in particular sample, have a great influence over the performance of a model. Displaying both allows for a more accurate and an easier management of their influence.\n",
    "\n",
    "3. train():\n",
    "Finally, trains the model.\n",
    "The loggings here are mainly useful for monitoring, making sure that no threads are executed instantaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The parameters:**\n",
    "- `min_count` = int - Ignores all words with total absolute frequency lower than this - (2, 100)\n",
    "- `window` = int - The maximum distance between the current and predicted word within a sentence. E.g. window words on the left and window words on the left of our target - (2, 10)\n",
    "- `size` = int - Dimensionality of the feature vectors. - (50, 300)\n",
    "- `sample` = float - The threshold for configuring which higher-frequency words are randomly downsampled. Highly influencial. - (0, 1e-5)\n",
    "- `alpha` = float - The initial learning rate - (0.01, 0.05)\n",
    "- `min_alpha` = float - Learning rate will linearly drop to min_alpha as training progresses. To set it: alpha - (min_alpha * epochs) ~ 0.00\n",
    "- `negative` = int - If > 0, negative sampling will be used, the int for negative specifies how many \"noise words\" should be drown. If set to 0, no negative sampling is used. - (5, 20)\n",
    "- `workers` = int - Use these many worker threads to train the model (=faster training with multicore machines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2,\n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Vocabulary Table:**\n",
    "\n",
    "\n",
    "Word2Vec requires us to build the vocabulary table (simply digesting all the words and filtering out the unique words, and doing some basic counts on them):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:21:56: collecting all words and their counts\n",
      "INFO - 00:21:56: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 00:21:56: PROGRESS: at sentence #10000, processed 64401 words, keeping 9172 word types\n",
      "INFO - 00:21:56: PROGRESS: at sentence #20000, processed 134240 words, keeping 14076 word types\n",
      "INFO - 00:21:56: PROGRESS: at sentence #30000, processed 198733 words, keeping 17077 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #40000, processed 258328 words, keeping 19781 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #50000, processed 319396 words, keeping 22103 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #60000, processed 383343 words, keeping 24333 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #70000, processed 447667 words, keeping 26389 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #80000, processed 511491 words, keeping 28323 word types\n",
      "INFO - 00:21:57: PROGRESS: at sentence #90000, processed 576428 words, keeping 29944 word types\n",
      "INFO - 00:21:58: collected 30248 word types from a corpus of 591008 raw words and 92173 sentences\n",
      "INFO - 00:21:58: Loading a fresh vocabulary\n",
      "INFO - 00:21:58: effective_min_count=20 retains 3381 unique words (11% of original 30248, drops 26867)\n",
      "INFO - 00:21:58: effective_min_count=20 leaves 504251 word corpus (85% of original 591008, drops 86757)\n",
      "INFO - 00:21:58: deleting the raw counts dictionary of 30248 items\n",
      "INFO - 00:21:58: sample=6e-05 downsamples 1097 most-common words\n",
      "INFO - 00:21:58: downsampling leaves estimated 218202 word corpus (43.3% of prior 504251)\n",
      "INFO - 00:21:58: estimated required memory for 3381 words and 300 dimensions: 9804900 bytes\n",
      "INFO - 00:21:58: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training of the model:**\n",
    "\n",
    "\n",
    "Parameters of the training:\n",
    "\n",
    "- total_examples = int - Count of sentences;\n",
    "- epochs = int - Number of iterations (epochs) over the corpus - [10, 20, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:22:50: training model with 7 workers on 3381 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 00:22:52: EPOCH 1 - PROGRESS: at 49.22% examples, 103730 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:52: EPOCH - 1 : training on 591008 raw words (218217 effective words) took 1.9s, 113769 effective words/s\n",
      "INFO - 00:22:53: EPOCH 2 - PROGRESS: at 59.38% examples, 122328 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:54: EPOCH - 2 : training on 591008 raw words (218258 effective words) took 1.8s, 119533 effective words/s\n",
      "INFO - 00:22:55: EPOCH 3 - PROGRESS: at 57.71% examples, 121485 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:56: EPOCH - 3 : training on 591008 raw words (218223 effective words) took 1.7s, 125369 effective words/s\n",
      "INFO - 00:22:57: EPOCH 4 - PROGRESS: at 52.62% examples, 110445 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:22:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:22:58: EPOCH - 4 : training on 591008 raw words (218081 effective words) took 2.0s, 111473 effective words/s\n",
      "INFO - 00:22:59: EPOCH 5 - PROGRESS: at 49.22% examples, 104105 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:00: EPOCH - 5 : training on 591008 raw words (218142 effective words) took 2.0s, 109986 effective words/s\n",
      "INFO - 00:23:01: EPOCH 6 - PROGRESS: at 52.62% examples, 111869 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:02: EPOCH 6 - PROGRESS: at 100.00% examples, 107415 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:23:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:02: EPOCH - 6 : training on 591008 raw words (218211 effective words) took 2.0s, 107340 effective words/s\n",
      "INFO - 00:23:03: EPOCH 7 - PROGRESS: at 52.62% examples, 108722 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:04: EPOCH - 7 : training on 591008 raw words (218083 effective words) took 1.9s, 113872 effective words/s\n",
      "INFO - 00:23:05: EPOCH 8 - PROGRESS: at 45.59% examples, 98657 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:06: EPOCH 8 - PROGRESS: at 93.36% examples, 101360 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:06: EPOCH - 8 : training on 591008 raw words (218169 effective words) took 2.1s, 104008 effective words/s\n",
      "INFO - 00:23:07: EPOCH 9 - PROGRESS: at 47.42% examples, 100069 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:08: EPOCH - 9 : training on 591008 raw words (218266 effective words) took 2.0s, 109292 effective words/s\n",
      "INFO - 00:23:09: EPOCH 10 - PROGRESS: at 50.94% examples, 105941 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:10: EPOCH 10 - PROGRESS: at 96.60% examples, 103035 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:10: EPOCH - 10 : training on 591008 raw words (217966 effective words) took 2.1s, 102603 effective words/s\n",
      "INFO - 00:23:11: EPOCH 11 - PROGRESS: at 38.04% examples, 83626 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:12: EPOCH 11 - PROGRESS: at 86.51% examples, 92537 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:23:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:13: EPOCH - 11 : training on 591008 raw words (218536 effective words) took 2.4s, 90200 effective words/s\n",
      "INFO - 00:23:14: EPOCH 12 - PROGRESS: at 52.62% examples, 113007 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:15: EPOCH 12 - PROGRESS: at 98.38% examples, 106477 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:15: EPOCH - 12 : training on 591008 raw words (217945 effective words) took 2.0s, 107367 effective words/s\n",
      "INFO - 00:23:16: EPOCH 13 - PROGRESS: at 29.27% examples, 62208 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:23:17: EPOCH 13 - PROGRESS: at 71.29% examples, 74336 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:17: EPOCH - 13 : training on 591008 raw words (217987 effective words) took 2.8s, 78694 effective words/s\n",
      "INFO - 00:23:19: EPOCH 14 - PROGRESS: at 45.59% examples, 94708 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:19: EPOCH - 14 : training on 591008 raw words (218640 effective words) took 2.0s, 109837 effective words/s\n",
      "INFO - 00:23:21: EPOCH 15 - PROGRESS: at 56.07% examples, 118069 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:21: EPOCH - 15 : training on 591008 raw words (218295 effective words) took 1.8s, 119604 effective words/s\n",
      "INFO - 00:23:22: EPOCH 16 - PROGRESS: at 54.33% examples, 115554 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:23: EPOCH - 16 : training on 591008 raw words (218370 effective words) took 1.8s, 119624 effective words/s\n",
      "INFO - 00:23:24: EPOCH 17 - PROGRESS: at 45.59% examples, 94858 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:25: EPOCH - 17 : training on 591008 raw words (218127 effective words) took 2.0s, 107751 effective words/s\n",
      "INFO - 00:23:26: EPOCH 18 - PROGRESS: at 39.86% examples, 86486 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 00:23:27: EPOCH 18 - PROGRESS: at 84.75% examples, 90113 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:28: EPOCH - 18 : training on 591008 raw words (218076 effective words) took 2.3s, 94649 effective words/s\n",
      "INFO - 00:23:29: EPOCH 19 - PROGRESS: at 54.33% examples, 111178 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:29: EPOCH - 19 : training on 591008 raw words (217751 effective words) took 1.9s, 115191 effective words/s\n",
      "INFO - 00:23:30: EPOCH 20 - PROGRESS: at 56.07% examples, 120936 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:31: EPOCH - 20 : training on 591008 raw words (218356 effective words) took 1.8s, 122732 effective words/s\n",
      "INFO - 00:23:32: EPOCH 21 - PROGRESS: at 52.62% examples, 112094 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:33: EPOCH - 21 : training on 591008 raw words (217655 effective words) took 1.8s, 121883 effective words/s\n",
      "INFO - 00:23:34: EPOCH 22 - PROGRESS: at 56.07% examples, 119993 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:23:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:35: EPOCH - 22 : training on 591008 raw words (218246 effective words) took 1.8s, 119960 effective words/s\n",
      "INFO - 00:23:36: EPOCH 23 - PROGRESS: at 57.71% examples, 123636 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:37: EPOCH - 23 : training on 591008 raw words (218315 effective words) took 1.7s, 128003 effective words/s\n",
      "INFO - 00:23:38: EPOCH 24 - PROGRESS: at 52.62% examples, 112889 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:38: EPOCH - 24 : training on 591008 raw words (217736 effective words) took 1.8s, 122115 effective words/s\n",
      "INFO - 00:23:39: EPOCH 25 - PROGRESS: at 54.33% examples, 112744 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:40: EPOCH - 25 : training on 591008 raw words (218156 effective words) took 1.8s, 122316 effective words/s\n",
      "INFO - 00:23:41: EPOCH 26 - PROGRESS: at 57.71% examples, 122882 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:42: EPOCH - 26 : training on 591008 raw words (217692 effective words) took 1.8s, 121868 effective words/s\n",
      "INFO - 00:23:43: EPOCH 27 - PROGRESS: at 57.71% examples, 124928 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:44: EPOCH - 27 : training on 591008 raw words (218334 effective words) took 1.8s, 124136 effective words/s\n",
      "INFO - 00:23:45: EPOCH 28 - PROGRESS: at 49.22% examples, 105528 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:46: EPOCH - 28 : training on 591008 raw words (217844 effective words) took 1.9s, 114877 effective words/s\n",
      "INFO - 00:23:47: EPOCH 29 - PROGRESS: at 50.94% examples, 104493 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:47: EPOCH - 29 : training on 591008 raw words (217902 effective words) took 1.9s, 114946 effective words/s\n",
      "INFO - 00:23:49: EPOCH 30 - PROGRESS: at 56.07% examples, 118373 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 00:23:50: EPOCH 30 - PROGRESS: at 98.20% examples, 104287 words/s, in_qsize 1, out_qsize 5\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 00:23:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 00:23:50: EPOCH - 30 : training on 591008 raw words (218346 effective words) took 2.1s, 105090 effective words/s\n",
      "INFO - 00:23:50: training on a 17730240 raw words (6543925 effective words) took 59.0s, 110826 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.99 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 00:24:25: precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exploring the model**\n",
    "\n",
    "Most similar to:\n",
    "    \n",
    "Here, we will ask our model to find the word most similar to some of the most iconic characters of the Simpsons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('depressed', 0.7351570129394531),\n",
       " ('marge', 0.7273886203765869),\n",
       " ('bongo', 0.7201482057571411),\n",
       " ('sweetheart', 0.7082821130752563),\n",
       " ('rude', 0.7049339413642883),\n",
       " ('embarrassing', 0.6905354261398315),\n",
       " ('unno', 0.6816667318344116),\n",
       " ('abe', 0.6753657460212708),\n",
       " ('eliza', 0.6622533798217773),\n",
       " ('snuggle', 0.6594163775444031)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67944306"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('maggie', 'baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6119868"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('bart', 'nelson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luoyifeng/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'milhouse'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The codes in this notebook take insipiration from various sources.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
